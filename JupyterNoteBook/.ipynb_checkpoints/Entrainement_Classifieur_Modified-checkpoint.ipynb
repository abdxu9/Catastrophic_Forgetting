{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9ba569-8c3a-4441-a950-83317b40104f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_ewc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, RandomizedSearchCV\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_ewc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelEWC\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtweet_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TweetDataset\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralNetwork\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model_ewc'"
     ]
    }
   ],
   "source": [
    "#Importation des bibliotheques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from model_ewc import ModelEWC\n",
    "\n",
    "from tweet_dataset import TweetDataset\n",
    "from neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf55efa-aa99-4e84-8dfe-9e937e037dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()  # To check memory usage after clearing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd948642-624b-4a48-befe-724c8a755461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition de constante\n",
    "SEED = 42 \n",
    "BATCH_SIZE = 64 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9815bfd7-8756-49d7-a420-d7e60301cab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Abdou/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "class OtherDataset(Dataset):\n",
    "    def __init__(self, encodings,\n",
    "                 tokenizer=torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased'),\n",
    "                 max_length=180):\n",
    "        self.encodings = encodings\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.encodings.iloc[index] if hasattr(self.encodings, 'iloc') else self.encodings[index]\n",
    "        inputs = self.tokenizer(\n",
    "            text=text['text'],\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = text['label']\n",
    "        # Use string comparison for labels\n",
    "        target = 0 if target == 'Negative' else 1# if target == 'Positive' else [0, 0,1 ]\n",
    "        \n",
    "        return {\n",
    "            'ids': inputs['input_ids'].squeeze(0).to(self.device),\n",
    "            'token_type_ids': inputs['token_type_ids'].squeeze(0).to(self.device),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0).to(self.device),\n",
    "            'target': torch.tensor(target, dtype=torch.float).to(self.device)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdou\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Chargement des donnÃ©es Twitter...\n",
      "ðŸ“Œ Chargement des donnÃ©es Bluesky...\n",
      "ðŸ“Œ EntraÃ®nement sur la tÃ¢che Twitter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdou\\Documents\\POLYTECH\\4A\\PROJET_4A\\model_ewc.py:295: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=self.to(self.device))  # Charger le fichier sur le bon device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ModÃ¨le chargÃ© depuis model_T2_B1_500_nofreeze, entraÃ®nÃ© pendant 2 Ã©poques.\n",
      " Optimisation de lambda EWC...\n",
      " Test avec lambda = 1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.0, 'accuracy': 0.56, 'roc_auc': np.float64(0.79)}\n",
      " Test avec lambda = 7498.942093324558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/1:   0%|                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 64  # Reduced from 64\n",
    "EPOCHS = 2\n",
    "EPOCHS_BLUESKY = 1\n",
    "NBDATA = 500\n",
    "LR = 3e-4\n",
    "FREEZE = False\n",
    "\n",
    "# Set CUDA memory allocation configuration\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory cache\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def prepare_twitter_data():\n",
    "    raw_dataset = load_dataset(\"EleutherAI/twitter-sentiment\")\n",
    "    dataset = raw_dataset.remove_columns([\"source\", \"id\"])\n",
    "    dataset = dataset.shuffle(seed=48)\n",
    "\n",
    "    # SÃ©lection d'un sous-Ã©chantillon\n",
    "    dataset = dataset[\"train\"].select(range(NBDATA))\n",
    "\n",
    "    # Split train/test\n",
    "    dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=48)\n",
    "    train_data = dataset['train']\n",
    "\n",
    "    # Split test/validation\n",
    "    generalisation_test = dataset['test'].train_test_split(test_size=0.5, shuffle=True, seed=48)\n",
    "    validation_data = generalisation_test[\"train\"]\n",
    "    test_data = generalisation_test[\"test\"]\n",
    "\n",
    "    # CrÃ©ation des datasets et dataloaders\n",
    "    train_dataset = TweetDataset(train_data)\n",
    "    val_dataset = TweetDataset(validation_data)\n",
    "    test_dataset = TweetDataset(test_data)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def prepare_bluesky_data():\n",
    "    df = pd.read_csv('bluesky.csv')\n",
    "    df = df.drop(['Unnamed: 0', 'score'], axis=1)\n",
    "    df = df[df['label'].isin(['Positive', 'Negative'])]\n",
    "\n",
    "    df = df.sample(n=1000, random_state=42)\n",
    "\n",
    "    # Split train/test/validation\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "    # CrÃ©ation des datasets et dataloaders\n",
    "    train_dataset = OtherDataset(train_df)\n",
    "    val_dataset = OtherDataset(val_df)\n",
    "    test_dataset = OtherDataset(test_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def evaluate_lambda(trainer, ewc_lambda, train_loader_twitter, train_loader_bluesky, val_loader_bluesky, test_loader_bluesky):\n",
    "    # Move to CPU temporarily for evaluation\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    trainer.activate_ewc(ewc_lambda=ewc_lambda)\n",
    "    trainer.compute_fisher_information(train_loader_twitter)\n",
    "    \n",
    "    trainer.set_loader(train_loader_bluesky, val_loader_bluesky)\n",
    "    trainer.train(n_epochs=EPOCHS_BLUESKY)\n",
    "    \n",
    "    result = trainer.predict(test_loader_bluesky)\n",
    "    \n",
    "    # Move back to GPU\n",
    "    trainer.model.to(DEVICE)\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # PrÃ©paration du modÃ¨le et des optimiseurs\n",
    "    model = NeuralNetwork(n_labels=1, freeze_params=FREEZE).to(DEVICE)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    trainer = ModelEWC(model, loss_fn, optimizer)\n",
    "\n",
    "    # Chargement des donnÃ©es\n",
    "    print(\"ðŸ“Œ Chargement des donnÃ©es Twitter...\")\n",
    "    train_loader_twitter, val_loader_twitter, test_loader_twitter = prepare_twitter_data()\n",
    "\n",
    "    print(\"ðŸ“Œ Chargement des donnÃ©es Bluesky...\")\n",
    "    train_loader_bluesky, val_loader_bluesky, test_loader_bluesky = prepare_bluesky_data()\n",
    "\n",
    "    # EntraÃ®nement sur Twitter\n",
    "    print(\"ðŸ“Œ EntraÃ®nement sur la tÃ¢che Twitter...\")\n",
    "    trainer.set_loader(train_loader_twitter, val_loader_twitter)\n",
    "    trainer.load_checkpoint('./Model/model_T2_B1_500_nofreeze')\n",
    "    \n",
    "    print(\" Optimisation de lambda EWC...\")\n",
    "    best_lambda = None\n",
    "    best_score = -np.inf\n",
    "    lambda_values = np.logspace(3, 10, num=9)\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    # Create model copy for lambda optimization\n",
    "    model_copy = copy.deepcopy(trainer.model)  # â† Nouvelle copie Ã  chaque itÃ©ration\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model_copy.parameters(), lr=LR)\n",
    "    trainer_temp = ModelEWC(model_copy, loss_fn, optimizer)\n",
    "    \n",
    "    for lmbda in lambda_values:\n",
    "        model_copy = copy.deepcopy(trainer.model)  # â† Nouvelle copie Ã  chaque itÃ©ration\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model_copy.parameters(), lr=LR)\n",
    "        trainer_temp = ModelEWC(model_copy, loss_fn, optimizer)\n",
    "        print(f\" Test avec lambda = {lmbda}\")\n",
    "        \n",
    "        score_dict = evaluate_lambda(trainer_temp, lmbda, train_loader_twitter, \n",
    "                                   train_loader_bluesky, val_loader_bluesky, test_loader_bluesky)\n",
    "        print(score_dict)\n",
    "        score = score_dict['f1_score'] + score_dict['accuracy'] + score_dict['roc_auc']\n",
    "        scores.append((lmbda, score_dict, score))\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_lambda = lmbda\n",
    "\n",
    "    print(f\" Meilleur lambda trouvÃ©: {best_lambda}\")\n",
    "\n",
    "    print(\" RÃ©sultats des tests de lambda:\")\n",
    "    for entry in scores:\n",
    "        lmbda, score_dict, combined_score = entry\n",
    "        print(f\"Lambda: {lmbda}, F1: {score_dict['f1_score']:.4f}, \"\n",
    "              f\"Accuracy: {score_dict['accuracy']:.4f}, ROC AUC: {score_dict['roc_auc']:.4f}, \"\n",
    "              f\"Combined: {combined_score:.4f}\")\n",
    "\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # Final training with best lambda\n",
    "    trainer_temp.activate_ewc(ewc_lambda=best_lambda)  # Use best_lambda instead of hardcoded value\n",
    "    trainer_temp.compute_fisher_information(train_loader_twitter)\n",
    "\n",
    "    print(\"ðŸ“Œ EntraÃ®nement sur la tÃ¢che Bluesky avec EWC...\")\n",
    "    trainer_temp.set_loader(train_loader_bluesky, val_loader_bluesky)\n",
    "    trainer_temp.train(n_epochs=EPOCHS_BLUESKY)\n",
    "\n",
    "    print(\" MÃ©triques sur Twitter aprÃ¨s EWC:\")\n",
    "    twitter_metrics = trainer_temp.predict(test_loader_twitter)\n",
    "    print(twitter_metrics)\n",
    "\n",
    "    print(\" MÃ©triques sur Bluesky aprÃ¨s EWC:\")\n",
    "    bluesky_metrics = trainer_temp.predict(test_loader_bluesky)\n",
    "    print(bluesky_metrics)\n",
    "\n",
    "    print(\"Affichage des courbes d'apprentissage...\")\n",
    "    trainer_temp.plot_losses()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f5c8e-a12b-4164-90d7-44190fa68366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
