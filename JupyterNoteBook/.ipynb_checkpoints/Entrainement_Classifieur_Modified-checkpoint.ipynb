{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9ba569-8c3a-4441-a950-83317b40104f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_ewc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, RandomizedSearchCV\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_ewc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelEWC\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtweet_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TweetDataset\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralNetwork\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model_ewc'"
     ]
    }
   ],
   "source": [
    "#Importation des bibliotheques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from model_ewc import ModelEWC\n",
    "\n",
    "from tweet_dataset import TweetDataset\n",
    "from neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf55efa-aa99-4e84-8dfe-9e937e037dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()  # To check memory usage after clearing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd948642-624b-4a48-befe-724c8a755461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition de constante\n",
    "SEED = 42 \n",
    "BATCH_SIZE = 64 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9815bfd7-8756-49d7-a420-d7e60301cab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Abdou/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n"
     ]
    }
   ],
   "source": [
    "class OtherDataset(Dataset):\n",
    "    def __init__(self, encodings,\n",
    "                 tokenizer=torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased'),\n",
    "                 max_length=180):\n",
    "        self.encodings = encodings\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.encodings.iloc[index] if hasattr(self.encodings, 'iloc') else self.encodings[index]\n",
    "        inputs = self.tokenizer(\n",
    "            text=text['text'],\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = text['label']\n",
    "        # Use string comparison for labels\n",
    "        target = 0 if target == 'Negative' else 1# if target == 'Positive' else [0, 0,1 ]\n",
    "        \n",
    "        return {\n",
    "            'ids': inputs['input_ids'].squeeze(0).to(self.device),\n",
    "            'token_type_ids': inputs['token_type_ids'].squeeze(0).to(self.device),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0).to(self.device),\n",
    "            'target': torch.tensor(target, dtype=torch.float).to(self.device)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdou\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Chargement des données Twitter...\n",
      "📌 Chargement des données Bluesky...\n",
      "📌 Entraînement sur la tâche Twitter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdou\\Documents\\POLYTECH\\4A\\PROJET_4A\\model_ewc.py:295: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, map_location=self.to(self.device))  # Charger le fichier sur le bon device\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modèle chargé depuis model_T2_B1_500_nofreeze, entraîné pendant 2 époques.\n",
      " Optimisation de lambda EWC...\n",
      " Test avec lambda = 1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.0, 'accuracy': 0.56, 'roc_auc': np.float64(0.79)}\n",
      " Test avec lambda = 7498.942093324558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/1:   0%|                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 64  # Reduced from 64\n",
    "EPOCHS = 2\n",
    "EPOCHS_BLUESKY = 1\n",
    "NBDATA = 500\n",
    "LR = 3e-4\n",
    "FREEZE = False\n",
    "\n",
    "# Set CUDA memory allocation configuration\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory cache\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def prepare_twitter_data():\n",
    "    raw_dataset = load_dataset(\"EleutherAI/twitter-sentiment\")\n",
    "    dataset = raw_dataset.remove_columns([\"source\", \"id\"])\n",
    "    dataset = dataset.shuffle(seed=48)\n",
    "\n",
    "    # Sélection d'un sous-échantillon\n",
    "    dataset = dataset[\"train\"].select(range(NBDATA))\n",
    "\n",
    "    # Split train/test\n",
    "    dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=48)\n",
    "    train_data = dataset['train']\n",
    "\n",
    "    # Split test/validation\n",
    "    generalisation_test = dataset['test'].train_test_split(test_size=0.5, shuffle=True, seed=48)\n",
    "    validation_data = generalisation_test[\"train\"]\n",
    "    test_data = generalisation_test[\"test\"]\n",
    "\n",
    "    # Création des datasets et dataloaders\n",
    "    train_dataset = TweetDataset(train_data)\n",
    "    val_dataset = TweetDataset(validation_data)\n",
    "    test_dataset = TweetDataset(test_data)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def prepare_bluesky_data():\n",
    "    df = pd.read_csv('bluesky.csv')\n",
    "    df = df.drop(['Unnamed: 0', 'score'], axis=1)\n",
    "    df = df[df['label'].isin(['Positive', 'Negative'])]\n",
    "\n",
    "    df = df.sample(n=1000, random_state=42)\n",
    "\n",
    "    # Split train/test/validation\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Création des datasets et dataloaders\n",
    "    train_dataset = OtherDataset(train_df)\n",
    "    val_dataset = OtherDataset(val_df)\n",
    "    test_dataset = OtherDataset(test_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def evaluate_lambda(trainer, ewc_lambda, train_loader_twitter, train_loader_bluesky, val_loader_bluesky, test_loader_bluesky):\n",
    "    # Move to CPU temporarily for evaluation\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    trainer.activate_ewc(ewc_lambda=ewc_lambda)\n",
    "    trainer.compute_fisher_information(train_loader_twitter)\n",
    "    \n",
    "    trainer.set_loader(train_loader_bluesky, val_loader_bluesky)\n",
    "    trainer.train(n_epochs=EPOCHS_BLUESKY)\n",
    "    \n",
    "    result = trainer.predict(test_loader_bluesky)\n",
    "    \n",
    "    # Move back to GPU\n",
    "    trainer.model.to(DEVICE)\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # Préparation du modèle et des optimiseurs\n",
    "    model = NeuralNetwork(n_labels=1, freeze_params=FREEZE).to(DEVICE)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    trainer = ModelEWC(model, loss_fn, optimizer)\n",
    "\n",
    "    # Chargement des données\n",
    "    print(\"📌 Chargement des données Twitter...\")\n",
    "    train_loader_twitter, val_loader_twitter, test_loader_twitter = prepare_twitter_data()\n",
    "\n",
    "    print(\"📌 Chargement des données Bluesky...\")\n",
    "    train_loader_bluesky, val_loader_bluesky, test_loader_bluesky = prepare_bluesky_data()\n",
    "\n",
    "    # Entraînement sur Twitter\n",
    "    print(\"📌 Entraînement sur la tâche Twitter...\")\n",
    "    trainer.set_loader(train_loader_twitter, val_loader_twitter)\n",
    "    trainer.load_checkpoint('./Model/model_T2_B1_500_nofreeze')\n",
    "    \n",
    "    print(\" Optimisation de lambda EWC...\")\n",
    "    best_lambda = None\n",
    "    best_score = -np.inf\n",
    "    lambda_values = np.logspace(3, 10, num=9)\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    # Create model copy for lambda optimization\n",
    "    model_copy = copy.deepcopy(trainer.model)  # ← Nouvelle copie à chaque itération\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model_copy.parameters(), lr=LR)\n",
    "    trainer_temp = ModelEWC(model_copy, loss_fn, optimizer)\n",
    "    \n",
    "    for lmbda in lambda_values:\n",
    "        model_copy = copy.deepcopy(trainer.model)  # ← Nouvelle copie à chaque itération\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model_copy.parameters(), lr=LR)\n",
    "        trainer_temp = ModelEWC(model_copy, loss_fn, optimizer)\n",
    "        print(f\" Test avec lambda = {lmbda}\")\n",
    "        \n",
    "        score_dict = evaluate_lambda(trainer_temp, lmbda, train_loader_twitter, \n",
    "                                   train_loader_bluesky, val_loader_bluesky, test_loader_bluesky)\n",
    "        print(score_dict)\n",
    "        score = score_dict['f1_score'] + score_dict['accuracy'] + score_dict['roc_auc']\n",
    "        scores.append((lmbda, score_dict, score))\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_lambda = lmbda\n",
    "\n",
    "    print(f\" Meilleur lambda trouvé: {best_lambda}\")\n",
    "\n",
    "    print(\" Résultats des tests de lambda:\")\n",
    "    for entry in scores:\n",
    "        lmbda, score_dict, combined_score = entry\n",
    "        print(f\"Lambda: {lmbda}, F1: {score_dict['f1_score']:.4f}, \"\n",
    "              f\"Accuracy: {score_dict['accuracy']:.4f}, ROC AUC: {score_dict['roc_auc']:.4f}, \"\n",
    "              f\"Combined: {combined_score:.4f}\")\n",
    "\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # Final training with best lambda\n",
    "    trainer_temp.activate_ewc(ewc_lambda=best_lambda)  # Use best_lambda instead of hardcoded value\n",
    "    trainer_temp.compute_fisher_information(train_loader_twitter)\n",
    "\n",
    "    print(\"📌 Entraînement sur la tâche Bluesky avec EWC...\")\n",
    "    trainer_temp.set_loader(train_loader_bluesky, val_loader_bluesky)\n",
    "    trainer_temp.train(n_epochs=EPOCHS_BLUESKY)\n",
    "\n",
    "    print(\" Métriques sur Twitter après EWC:\")\n",
    "    twitter_metrics = trainer_temp.predict(test_loader_twitter)\n",
    "    print(twitter_metrics)\n",
    "\n",
    "    print(\" Métriques sur Bluesky après EWC:\")\n",
    "    bluesky_metrics = trainer_temp.predict(test_loader_bluesky)\n",
    "    print(bluesky_metrics)\n",
    "\n",
    "    print(\"Affichage des courbes d'apprentissage...\")\n",
    "    trainer_temp.plot_losses()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f5c8e-a12b-4164-90d7-44190fa68366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
