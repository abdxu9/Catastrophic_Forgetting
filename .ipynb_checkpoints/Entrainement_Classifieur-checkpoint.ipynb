{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ba569-8c3a-4441-a950-83317b40104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des bibliotheques\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchviz import make_dot\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from model import Model\n",
    "from tweet_dataset import TweetDataset\n",
    "from neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948642-624b-4a48-befe-724c8a755461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition de constante\n",
    "SEED = 42 \n",
    "BATCH_SIZE = 64 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "EPOCHS = 2\n",
    "EPOCHS_BLUSKY = 1\n",
    "NBDATA = 500\n",
    "LR = 3e-5\n",
    "FREEZE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78dfd0-dcdf-4a5e-b5cd-664723058492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement de notre dataset d'entrainement\n",
    "raw_dataset = load_dataset(\"EleutherAI/twitter-sentiment\")\n",
    "\n",
    "#On a pas besoin de la colonne unnamed\n",
    "dataset = raw_dataset.remove_columns(\"source\")\n",
    "dataset = dataset.remove_columns(\"id\")\n",
    "\n",
    "#Les donnees étaient rangés dans l'ordre des sentiments \n",
    "dataset = dataset.shuffle(seed=48)\n",
    "\n",
    "#On va prendre NBDATA tweets pour entrainer et tester notre model\n",
    "dataset = dataset[\"train\"].select(range(NBDATA))\n",
    "\n",
    "#creation des dataset de train-validation-test\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed = 48)\n",
    "train_data = dataset['train']\n",
    "generalisation_test = dataset['test'].train_test_split(test_size=0.5,shuffle=True, seed = 48)\n",
    "validation_data = generalisation_test[\"train\"]\n",
    "test_data = generalisation_test[\"test\"]\n",
    "from collections import Counter\n",
    "\n",
    "def count_classes(dataset, label_column=\"label\"):\n",
    "    labels = [example[label_column] for example in dataset]\n",
    "    return Counter(labels)\n",
    "\n",
    "print(\"Train:\", count_classes(train_data))\n",
    "print(\"Validation:\", count_classes(validation_data))\n",
    "print(\"Test:\", count_classes(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6892ab6-5ca3-41cb-af65-c7aea711e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TweetDataset(train_data)\n",
    "validation_data = TweetDataset(validation_data)\n",
    "test_data = TweetDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339709b-5aa9-4f2e-9f44-ef0682b79050",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(n_labels=1, freeze_params=FREEZE).to(DEVICE)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4607491-0d36-4afa-b34f-ec208f23ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs = Model(model, loss_fn, optimizer)\n",
    "sbs.set_seed()\n",
    "twitter_train_dataloader = DataLoader(train_data, batch_size=64, shuffle=False, num_workers = 0)\n",
    "twitter_validation_dataloader = DataLoader(validation_data, batch_size=64, shuffle=False, num_workers = 0)\n",
    "twitter_test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers = 0)\n",
    "sbs.set_loader(twitter_train_dataloader, twitter_validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0b316-b7de-4a3d-916b-9c6520439008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_train = time.time()\n",
    "sbs.train(n_epochs=EPOCHS)\n",
    "sbs.metrics()\n",
    "end_train = time.time()\n",
    "print(f'Execution time : {end_train - start_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da182ede-b6f3-4776-861e-80d192f6f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.plot_losses(\"C:\\\\Users\\\\Abdou\\\\Documents\\\\POLYTECH\\\\4A\\\\PROJET_4A\\\\IMAGE\\\\{NBDATA}_{EPOCHS}_{FREEZE}_{LR}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9cc0f-6d87-4171-beb1-16366333b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.predict(twitter_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311c2ad-924a-42a9-b3b0-55a1b87f2dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sbs.save_checkpoint('./Model/model_T2_B1_500_nofreeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c508d4-d5df-4590-84b3-7523cc37eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sbs.load_checkpoint('./Model/model_T2_B1_500_nofreeze')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51efe82-dba5-4d04-8683-8e09049de90b",
   "metadata": {},
   "source": [
    "## Test sur d'autre jeux de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85baa3-3aa6-4f17-a7c8-026fb2025761",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"PrkhrAwsti/Twitter_Sentiment_3M\")\n",
    "#On a pas besoin de la colonne unnamed\n",
    "ds = ds.remove_columns(\"Unnamed: 0\")\n",
    "\n",
    "ds = ds.shuffle(seed=48)\n",
    "ds = ds[\"train\"].select(range(10000))\n",
    "\n",
    "ds = ds.map(lambda example: {'label': example['sentiment'], 'text': example['tweet']}, remove_columns=['sentiment','tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073ee74-df43-4f61-ac34-6a69de552c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = TweetDataset(ds)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "sbs.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a222d16-abf5-49d2-bd51-fc0132d6fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtherDataset(Dataset):\n",
    "    def __init__(self, encodings,\n",
    "                 tokenizer=torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased'),\n",
    "                 max_length=180):\n",
    "        self.encodings = encodings\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.encodings.iloc[index] if hasattr(self.encodings, 'iloc') else self.encodings[index]\n",
    "        inputs = self.tokenizer(\n",
    "            text=text['text'],\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = text['label']\n",
    "        # Use string comparison for labels\n",
    "        target = 0 if target == 'Negative' else 1# if target == 'Positive' else [0, 0,1 ]\n",
    "        \n",
    "        return {\n",
    "            'ids': inputs['input_ids'].squeeze(0).to(self.device),\n",
    "            'token_type_ids': inputs['token_type_ids'].squeeze(0).to(self.device),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0).to(self.device),\n",
    "            'target': torch.tensor(target, dtype=torch.float).to(self.device)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8866097-b6fc-407a-b4f0-147e4012381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bluesky = pd.read_csv('bluesky.csv')\n",
    "df_bluesky = df_bluesky.drop(['Unnamed: 0','score'],axis=1)\n",
    "df_bluesky = df_bluesky[df_bluesky['label'].isin(['Positive', 'Negative'])]\n",
    "test_data = OtherDataset(df_bluesky)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "sbs.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb205672-2cf0-4707-bfc4-7211f20d212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"cardiffnlp/tweet_sentiment_multilingual\", \"english\")\n",
    "test = TweetDataset(ds[\"train\"].filter(lambda exemple: exemple['label'] in [0, 2]))\n",
    "test_dataloader = DataLoader(test, batch_size=BATCH_SIZE)\n",
    "sbs.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae711a1-7b6d-4734-bde5-933cc7c97023",
   "metadata": {},
   "source": [
    "## Transfert Learning sur Bleusky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795587af-d3fe-44b1-882c-909ac53452d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_bluesky = df_bluesky.sample(n=1000, random_state=SEED)\n",
    "\n",
    "# Split train/test/validation\n",
    "train_df, temp_df = train_test_split(df_bluesky, test_size=0.2, random_state=SEED)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED)\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = OtherDataset(train_df)\n",
    "val_dataset = OtherDataset(val_df)\n",
    "test_dataset = OtherDataset(test_df)\n",
    "\n",
    "# Création des dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce1e18-e40f-4f98-83d5-494e149f3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.set_loader(train_loader, val_loader)\n",
    "start_train = time.time()\n",
    "sbs.train(n_epochs=EPOCHS_BLUSKY )\n",
    "sbs.metrics()\n",
    "end_train = time.time()\n",
    "print(f'Execution time : {end_train - start_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5edbce-db36-490f-bdeb-12f22742ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988f4d1-0ee4-413a-b2d0-818de508971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.predict(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77997072-eaa3-4c39-ac20-6f966ca47b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.predict(twitter_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf02d0e-3ee7-47b8-b546-0787b188d6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
