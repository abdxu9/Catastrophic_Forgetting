{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ba569-8c3a-4441-a950-83317b40104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des bibliotheques\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from model_ewc import ModelEWC\n",
    "\n",
    "from tweet_dataset import TweetDataset\n",
    "from neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf55efa-aa99-4e84-8dfe-9e937e037dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()  # To check memory usage after clearing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd948642-624b-4a48-befe-724c8a755461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition de constante\n",
    "SEED = 42 \n",
    "BATCH_SIZE = 64 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815bfd7-8756-49d7-a420-d7e60301cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OtherDataset(Dataset):\n",
    "    def __init__(self, encodings,\n",
    "                 tokenizer=torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased'),\n",
    "                 max_length=180):\n",
    "        self.encodings = encodings\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.encodings.iloc[index] if hasattr(self.encodings, 'iloc') else self.encodings[index]\n",
    "        inputs = self.tokenizer(\n",
    "            text=text['text'],\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target = text['label']\n",
    "        # Use string comparison for labels\n",
    "        target = 0 if target == 'Negative' else 1# if target == 'Positive' else [0, 0,1 ]\n",
    "        \n",
    "        return {\n",
    "            'ids': inputs['input_ids'].squeeze(0).to(self.device),\n",
    "            'token_type_ids': inputs['token_type_ids'].squeeze(0).to(self.device),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0).to(self.device),\n",
    "            'target': torch.tensor(target, dtype=torch.float).to(self.device)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 64  # Reduced from 64\n",
    "EPOCHS = 2\n",
    "EPOCHS_BLUESKY = 1\n",
    "NBDATA = 500\n",
    "LR = 3e-4\n",
    "FREEZE = False\n",
    "\n",
    "# Set CUDA memory allocation configuration\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory cache\"\"\"\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def prepare_twitter_data():\n",
    "    raw_dataset = load_dataset(\"EleutherAI/twitter-sentiment\")\n",
    "    dataset = raw_dataset.remove_columns([\"source\", \"id\"])\n",
    "    dataset = dataset.shuffle(seed=48)\n",
    "\n",
    "    # Sélection d'un sous-échantillon\n",
    "    dataset = dataset[\"train\"].select(range(NBDATA))\n",
    "\n",
    "    # Split train/test\n",
    "    dataset = dataset.train_test_split(test_size=0.2, shuffle=True, seed=48)\n",
    "    train_data = dataset['train']\n",
    "\n",
    "    # Split test/validation\n",
    "    generalisation_test = dataset['test'].train_test_split(test_size=0.5, shuffle=True, seed=48)\n",
    "    validation_data = generalisation_test[\"train\"]\n",
    "    test_data = generalisation_test[\"test\"]\n",
    "\n",
    "    # Création des datasets et dataloaders\n",
    "    train_dataset = TweetDataset(train_data)\n",
    "    val_dataset = TweetDataset(validation_data)\n",
    "    test_dataset = TweetDataset(test_data)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def prepare_bluesky_data():\n",
    "    df = pd.read_csv('bluesky.csv')\n",
    "    df = df.drop(['Unnamed: 0', 'score'], axis=1)\n",
    "    df = df[df['label'].isin(['Positive', 'Negative'])]\n",
    "\n",
    "    df = df.sample(n=1000, random_state=42)\n",
    "\n",
    "    # Split train/test/validation\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Création des datasets et dataloaders\n",
    "    train_dataset = OtherDataset(train_df)\n",
    "    val_dataset = OtherDataset(val_df)\n",
    "    test_dataset = OtherDataset(test_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def evaluate_lambda(trainer, ewc_lambda, train_loader_twitter, train_loader_bluesky, val_loader_bluesky, test_loader_bluesky):\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    trainer.activate_ewc(ewc_lambda=ewc_lambda)\n",
    "    trainer.compute_fisher_information(train_loader_twitter)\n",
    "    \n",
    "    trainer.set_loader(train_loader_bluesky, val_loader_bluesky)\n",
    "    trainer.train(n_epochs=EPOCHS_BLUESKY)\n",
    "    \n",
    "    result = trainer.predict(test_loader_bluesky)\n",
    " \n",
    "    trainer.model.to(DEVICE)\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # Préparation du modèle et des optimiseurs\n",
    "    model = NeuralNetwork(n_labels=1, freeze_params=FREEZE).to(DEVICE)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    trainer = ModelEWC(model, loss_fn, optimizer)\n",
    "\n",
    "    # Chargement des données\n",
    "    print(\"Chargement des données Twitter...\")\n",
    "    train_loader_twitter, val_loader_twitter, test_loader_twitter = prepare_twitter_data()\n",
    "\n",
    "    print(\"Chargement des données Bluesky...\")\n",
    "    train_loader_bluesky, val_loader_bluesky, test_loader_bluesky = prepare_bluesky_data()\n",
    "\n",
    "    # Entraînement sur Twitter\n",
    "    print(\"Entraînement sur la tâche Twitter...\")\n",
    "    trainer.set_loader(train_loader_twitter, val_loader_twitter)\n",
    "    trainer.load_checkpoint('./Model/model_T2_B1_500_nofreeze')\n",
    "    \n",
    "    print(\"Optimisation de lambda EWC...\")\n",
    "    best_lambda = None\n",
    "    best_score = -np.inf\n",
    "    lambda_values = np.logspace(3, 10, num=9)\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    # Create model copy for lambda optimization\n",
    "    model_copy = copy.deepcopy(trainer.model)  # ← Nouvelle copie à chaque itération\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model_copy.parameters(), lr=LR)\n",
    "    trainer_temp = ModelEWC(model_copy, loss_fn, optimizer)\n",
    "    \n",
    "    for lmbda in lambda_values:\n",
    "        model_copy = copy.deepcopy(trainer.model)  # ← Nouvelle copie à chaque itération\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model_copy.parameters(), lr=LR)\n",
    "        trainer_temp = ModelEWC(model_copy, loss_fn, optimizer)\n",
    "        print(f\" Test avec lambda = {lmbda}\")\n",
    "        \n",
    "        score_dict = evaluate_lambda(trainer_temp, lmbda, train_loader_twitter, \n",
    "                                   train_loader_bluesky, val_loader_bluesky, test_loader_bluesky)\n",
    "        print(score_dict)\n",
    "        score = score_dict['f1_score'] + score_dict['accuracy'] + score_dict['roc_auc']\n",
    "        scores.append((lmbda, score_dict, score))\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_lambda = lmbda\n",
    "\n",
    "    print(f\"Meilleur lambda trouvé: {best_lambda}\")\n",
    "\n",
    "    print(\"Résultats des tests de lambda:\")\n",
    "    for entry in scores:\n",
    "        lmbda, score_dict, combined_score = entry\n",
    "        print(f\"Lambda: {lmbda}, F1: {score_dict['f1_score']:.4f}, \"\n",
    "              f\"Accuracy: {score_dict['accuracy']:.4f}, ROC AUC: {score_dict['roc_auc']:.4f}, \"\n",
    "              f\"Combined: {combined_score:.4f}\")\n",
    "\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # Final training with best lambda\n",
    "    trainer_temp.activate_ewc(ewc_lambda=best_lambda)  # Use best_lambda instead of hardcoded value\n",
    "    trainer_temp.compute_fisher_information(train_loader_twitter)\n",
    "\n",
    "    print(\"Entraînement sur la tâche Bluesky avec EWC...\")\n",
    "    trainer_temp.set_loader(train_loader_bluesky, val_loader_bluesky)\n",
    "    trainer_temp.train(n_epochs=EPOCHS_BLUESKY)\n",
    "\n",
    "    print(\"Métriques sur Twitter après EWC:\")\n",
    "    twitter_metrics = trainer_temp.predict(test_loader_twitter)\n",
    "    print(twitter_metrics)\n",
    "\n",
    "    print(\"Métriques sur Bluesky après EWC:\")\n",
    "    bluesky_metrics = trainer_temp.predict(test_loader_bluesky)\n",
    "    print(bluesky_metrics)\n",
    "\n",
    "    print(\"Affichage des courbes d'apprentissage...\")\n",
    "    trainer_temp.plot_losses()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f5c8e-a12b-4164-90d7-44190fa68366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
